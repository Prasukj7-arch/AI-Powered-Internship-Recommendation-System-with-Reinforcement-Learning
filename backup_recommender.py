"""
Backup Recommendation System using ChromaDB + Ollama
This serves as a fallback when OpenRouter API fails or limits are reached
"""

import pandas as pd
import os
import re
import chromadb
import ollama
from typing import List, Dict, Any
import warnings
warnings.filterwarnings('ignore')

class BackupRecommender:
    def __init__(self, csv_file_path: str):
        """
        Initialize the Backup Recommender with ChromaDB + Ollama
        
        Args:
            csv_file_path: Path to the CSV file containing internship data
        """
        self.csv_file_path = csv_file_path
        self.df = None
        self.collection = None
        self.embedding_fn = None
        self.load_data()
        self.setup_chromadb()
        
    def load_data(self):
        """Load and preprocess the internship data"""
        try:
            self.df = pd.read_csv(self.csv_file_path)
            print(f"âœ… Backup: Loaded {len(self.df)} internships from {self.csv_file_path}")
            
            # Create a combined description for embedding
            self.df['description'] = (
                self.df['Internship Title'].astype(str) + " at " +
                self.df['Company Name'].astype(str) + " | Location: " +
                self.df['Location'].astype(str) + ", " +
                self.df['State/UT'].astype(str) + " | Skills: " +
                self.df['Preferred Skill(s)'].astype(str) + " | Qualification: " +
                self.df['Minimum Qualification'].astype(str) + " | Sector: " +
                self.df['Sector'].astype(str) + " | Area: " +
                self.df['Area/Field'].astype(str)
            )
            
            print("âœ… Backup: Data preprocessing completed")
            
        except Exception as e:
            print(f"âŒ Backup: Error loading data: {e}")
            raise
    
    def setup_chromadb(self):
        """Setup ChromaDB with Ollama embeddings"""
        try:
            # Check if Ollama is available
            try:
                ollama.list()
                print("âœ… Backup: Ollama is available")
            except Exception as e:
                print(f"âŒ Backup: Ollama not available: {e}")
                raise
            
            # Setup embedding function
            self.embedding_fn = OllamaEmbeddingFunction(model="mxbai-embed-large")
            
            # Setup ChromaDB
            PERSIST_DIR = "chroma_storage"
            chroma_client = chromadb.PersistentClient(path=PERSIST_DIR)
            
            # Use existing collection if already created
            try:
                self.collection = chroma_client.get_collection(
                    name="internships", embedding_function=self.embedding_fn
                )
                print("âœ… Backup: Loaded existing Chroma collection from disk")
            except:
                self.collection = chroma_client.create_collection(
                    name="internships", embedding_function=self.embedding_fn
                )
                print("âœ… Backup: Created new Chroma collection")
                self.populate_chromadb()
                
        except Exception as e:
            print(f"âŒ Backup: Error setting up ChromaDB: {e}")
            raise
    
    def populate_chromadb(self):
        """Populate ChromaDB with internship data"""
        try:
            if self.collection.count() == 0:
                print("ðŸ”„ Backup: Populating ChromaDB with internship data...")
                BATCH_SIZE = 100
                all_docs, all_ids = [], []

                for idx, desc in enumerate(self.df['description'].tolist()):
                    chunks = self.chunk_text(desc, chunk_size=300, overlap=50)
                    for j, chunk in enumerate(chunks):
                        all_docs.append(chunk)
                        all_ids.append(f"{idx}_{j}")

                for i in range(0, len(all_docs), BATCH_SIZE):
                    batch_docs = all_docs[i:i+BATCH_SIZE]
                    batch_ids = all_ids[i:i+BATCH_SIZE]
                    self.collection.add(documents=batch_docs, ids=batch_ids)
                    print(f"âœ… Backup: Inserted batch {i//BATCH_SIZE + 1} with {len(batch_docs)} chunks")
            else:
                print(f"âœ… Backup: ChromaDB already populated with {self.collection.count()} chunks")
                
        except Exception as e:
            print(f"âŒ Backup: Error populating ChromaDB: {e}")
            raise
    
    def chunk_text(self, text: str, chunk_size: int = 300, overlap: int = 50) -> List[str]:
        """Chunk text into smaller pieces"""
        chunks = []
        start = 0
        while start < len(text):
            end = start + chunk_size
            chunk = text[start:end]
            chunks.append(chunk.strip())
            start += chunk_size - overlap
        return chunks
    
    def create_candidate_profile_text(self, resume_data: Dict[str, Any]) -> str:
        """Create a text profile from candidate data"""
        profile = f"""
        CANDIDATE PROFILE:
        Name: {resume_data.get('name', 'N/A')}
        Education: {resume_data.get('education', 'N/A')}
        Skills: {resume_data.get('skills', 'N/A')}
        Experience: {resume_data.get('experience', 'N/A')}
        Interests: {resume_data.get('interests', 'N/A')}
        Location Preference: {resume_data.get('location_preference', 'N/A')}
        Career Goals: {resume_data.get('career_goals', 'N/A')}
        Certifications: {resume_data.get('certifications', 'N/A')}
        Projects: {resume_data.get('projects', 'N/A')}
        """
        return profile.strip()
    
    def get_recommendations(self, resume_data: Dict[str, Any], num_recommendations: int = 5) -> List[Dict]:
        """
        Get recommendations using ChromaDB + Ollama
        
        Args:
            resume_data: Dictionary containing candidate information
            num_recommendations: Number of recommendations to return
        
        Returns:
            List of recommendation dictionaries
        """
        try:
            print("ðŸ”„ Backup: Starting ChromaDB + Ollama recommendation process...")
            
            # Create candidate profile text
            candidate_profile = self.create_candidate_profile_text(resume_data)
            
            # Chunk candidate profile
            resume_chunks = self.chunk_text(candidate_profile, chunk_size=400, overlap=50)
            print(f"âœ… Backup: Profile split into {len(resume_chunks)} chunks")
            
            # Query matches
            top_n = num_recommendations * 2  # Get more to filter
            all_matches = []

            for chunk in resume_chunks:
                results = self.collection.query(query_texts=[chunk], n_results=top_n)
                top_ids = results['ids'][0]
                top_texts = results['documents'][0]
                top_scores = results.get('distances', [[]])[0]

                raw_confidences = [1 - s for s in top_scores]
                min_c, max_c = min(raw_confidences), max(raw_confidences)
                normalized_confidences = [
                    100 * (c - min_c) / (max_c - min_c + 1e-8) for c in raw_confidences
                ]

                for iid, text, conf in zip(top_ids, top_texts, normalized_confidences):
                    all_matches.append((iid, text, conf))

            # Deduplicate and sort
            all_matches = sorted(all_matches, key=lambda x: x[2], reverse=True)
            seen = set()
            unique_matches = []
            for iid, text, conf in all_matches:
                if iid not in seen:
                    unique_matches.append((iid, text, conf))
                    seen.add(iid)
                if len(unique_matches) >= num_recommendations:
                    break

            # Convert to recommendation format
            recommendations = []
            for idx, (iid, text, conf) in enumerate(unique_matches[:num_recommendations]):
                # Extract company and title from text
                parts = text.split(" at ")
                if len(parts) >= 2:
                    title = parts[0]
                    company = parts[1].split(" |")[0]
                else:
                    title = "Internship"
                    company = "Company"
                
                # Calculate match percentage (ensure it's in 75-95% range)
                match_percentage = max(75, min(95, int(conf)))
                
                recommendations.append({
                    "rank": idx + 1,
                    "company": company,
                    "title": title,
                    "match_score": match_percentage,
                    "reasoning": f"Strong match based on skills and location alignment. Confidence: {conf:.1f}%",
                    "skills_to_highlight": self.extract_skills_from_text(text)
                })
            
            print(f"âœ… Backup: Generated {len(recommendations)} recommendations")
            return recommendations
            
        except Exception as e:
            print(f"âŒ Backup: Error getting recommendations: {e}")
            return self.create_fallback_recommendations(num_recommendations)
    
    def extract_skills_from_text(self, text: str) -> List[str]:
        """Extract skills from internship description text"""
        try:
            if "Skills:" in text:
                skills_part = text.split("Skills:")[-1].split("|")[0]
                skills = [skill.strip() for skill in skills_part.split(",") if skill.strip()]
                return skills[:5]  # Limit to 5 skills
            return ["Communication", "Teamwork"]
        except:
            return ["Communication", "Teamwork"]
    
    def create_fallback_recommendations(self, num_recommendations: int) -> List[Dict]:
        """Create basic fallback recommendations"""
        recommendations = []
        for idx in range(num_recommendations):
            if idx < len(self.df):
                internship = self.df.iloc[idx]
                recommendations.append({
                    "rank": idx + 1,
                    "company": internship['Company Name'],
                    "title": internship['Internship Title'],
                    "match_score": 75 + (idx * 2),
                    "reasoning": f"Good match based on {internship['Sector']} sector and {internship['Area/Field']} field",
                    "skills_to_highlight": internship['Preferred Skill(s)'].split(', ') if pd.notna(internship['Preferred Skill(s)']) else ["Communication", "Teamwork"]
                })
        return recommendations

class OllamaEmbeddingFunction:
    """Ollama embedding function for ChromaDB"""
    def __init__(self, model: str = "mxbai-embed-large"):
        self.model = model

    def __call__(self, input):
        if isinstance(input, str):
            input = [input]
        embeddings = []
        for t in input:
            try:
                response = ollama.embeddings(model=self.model, prompt=t)
                embeddings.append(response["embedding"])
            except Exception as e:
                print(f"âš ï¸ Backup: Ollama embedding error: {e}")
                # Return zero vector as fallback
                embeddings.append([0.0] * 1024)  # mxbai-embed-large has 1024 dimensions
        return embeddings

def test_backup_system():
    """Test the backup system"""
    try:
        print("ðŸ§ª Testing Backup Recommendation System")
        print("="*50)
        
        # Initialize backup recommender
        backup = BackupRecommender("internships_all_streams_edited.csv")
        
        # Sample candidate data
        sample_resume = {
            "name": "Priya Sharma",
            "education": "B.Tech Computer Science Engineering, 2024 - 8.5 CGPA",
            "skills": "Python, Machine Learning, TensorFlow, Data Analysis, SQL, Tableau, Web Development, JavaScript, React, Communication, Teamwork",
            "experience": "2 months data science internship at TechCorp, 1 year coding experience with personal projects, 6 months freelance web development",
            "interests": "Artificial Intelligence, Machine Learning, Data Science, Software Development, Fintech, Healthcare Technology",
            "location_preference": "Bangalore, Pune, Delhi, Mumbai, Hyderabad",
            "career_goals": "Become a senior data scientist in a leading tech company, work on AI/ML products that impact millions of users",
            "certifications": "Google Data Analytics Certificate, AWS Cloud Practitioner",
            "projects": "Built ML model for stock prediction, Developed e-commerce website, Created data visualization dashboard"
        }
        
        # Get recommendations
        recommendations = backup.get_recommendations(sample_resume, num_recommendations=5)
        
        # Display results
        print("\nðŸŽ¯ BACKUP RECOMMENDATIONS:")
        print("="*50)
        
        for rec in recommendations:
            print(f"\n#{rec['rank']} - {rec['company']} - {rec['title']}")
            print(f"   Match Score: {rec['match_score']}%")
            print(f"   Reasoning: {rec['reasoning']}")
            print(f"   Skills to Highlight: {', '.join(rec['skills_to_highlight'])}")
            print("-" * 40)
        
        print(f"\nâœ… Backup system test completed successfully!")
        return True
        
    except Exception as e:
        print(f"âŒ Backup system test failed: {e}")
        return False

if __name__ == "__main__":
    test_backup_system()
